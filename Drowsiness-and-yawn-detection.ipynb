{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zein-Zeus/drowsiness-and-yawn-detection/blob/main/Drowsiness-and-yawn-detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#problem statement:The goal is to create a complete prototype that can be\n",
        "#integrated into vehicles to enhance road safety.\n",
        "from imutils.video import VideoStream\n",
        "from imutils import face_utils\n",
        "from threading import Thread\n",
        "import numpy as np\n",
        "import argparse\n",
        "import imutils\n",
        "import time\n",
        "import dlib\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "# Define a function to trigger an alarm message\n",
        "def alarm(msg):\n",
        "    global alarm_status\n",
        "    global alarm_status2\n",
        "    global saying\n",
        "\n",
        "    while alarm_status:\n",
        "        print('call')\n",
        "        s = 'espeak \"'+msg+'\"'\n",
        "        os.system(s)\n",
        "\n",
        "    if alarm_status2:\n",
        "        print('call')\n",
        "        saying = True\n",
        "        s = 'espeak \"' + msg + '\"'\n",
        "        os.system(s)\n",
        "        saying = False\n",
        "\n",
        "# Define a function to calculate the eye aspect ratio (EAR)\n",
        "def eye_aspect_ratio(eye):\n",
        "    A = dist.euclidean(eye[1], eye[5])\n",
        "    B = dist.euclidean(eye[2], eye[4])\n",
        "\n",
        "    C = dist.euclidean(eye[0], eye[3])\n",
        "\n",
        "    ear = (A + B) / (2.0 * C)\n",
        "\n",
        "    return ear\n",
        "\n",
        "# Define a function to calculate the final EAR for both eyes\n",
        "def final_ear(shape):\n",
        "    (lStart, lEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"left_eye\"]\n",
        "    (rStart, rEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"right_eye\"]\n",
        "\n",
        "    leftEye = shape[lStart:lEnd]\n",
        "    rightEye = shape[rStart:rEnd]\n",
        "\n",
        "    leftEAR = eye_aspect_ratio(leftEye)\n",
        "    rightEAR = eye_aspect_ratio(rightEye)\n",
        "\n",
        "    ear = (leftEAR + rightEAR) / 2.0\n",
        "    return (ear, leftEye, rightEye)\n",
        "\n",
        "# Define a function to calculate lip distance for yawn detection\n",
        "def lip_distance(shape):\n",
        "    top_lip = shape[50:53]\n",
        "    top_lip = np.concatenate((top_lip, shape[61:64]))\n",
        "\n",
        "    low_lip = shape[56:59]\n",
        "    low_lip = np.concatenate((low_lip, shape[65:68]))\n",
        "\n",
        "    top_mean = np.mean(top_lip, axis=0)\n",
        "    low_mean = np.mean(low_lip, axis=0)\n",
        "\n",
        "    distance = abs(top_mean[1] - low_mean[1])\n",
        "    return distance\n",
        "\n",
        "# Parse command line arguments\n",
        "ap = argparse.ArgumentParser()\n",
        "ap.add_argument(\"-w\", \"--webcam\", type=int, default=0,\n",
        "                help=\"index of the webcam on the system\")\n",
        "args = vars(ap.parse_args())\n",
        "\n",
        "# Define thresholds and counters\n",
        "EYE_AR_THRESH = 0.3\n",
        "EYE_AR_CONSEC_FRAMES = 30\n",
        "YAWN_THRESH = 20\n",
        "alarm_status = False\n",
        "alarm_status2 = False\n",
        "saying = False\n",
        "COUNTER = 0\n",
        "\n",
        "# Load face detection and shape prediction models\n",
        "print(\"-> Loading the predictor and detector...\")\n",
        "detector = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")  # Use Colab's built-in Haar Cascade\n",
        "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
        "\n",
        "# Start the video stream using Colab's webcam capture\n",
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "    js = Javascript('''\n",
        "        async function takePhoto(quality) {\n",
        "          const div = document.createElement('div');\n",
        "          const capture = document.createElement('button');\n",
        "          capture.textContent = 'Capture';\n",
        "          div.appendChild(capture);\n",
        "\n",
        "          const video = document.createElement('video');\n",
        "          video.style.display = 'block';\n",
        "          const stream = await navigator.mediaDevices.getUserMedia({ 'audio': false, 'video': true });\n",
        "          document.body.appendChild(div);\n",
        "          div.appendChild(video);\n",
        "          video.srcObject = stream;\n",
        "          await video.play();\n",
        "\n",
        "          // Resize the output to fit the video element.\n",
        "          google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "          // Wait for Capture to be clicked.\n",
        "          const result = await new Promise(async (resolve) => {\n",
        "            capture.onclick = () => {\n",
        "              const canvas = document.createElement('canvas');\n",
        "              canvas.width = video.videoWidth;\n",
        "              canvas.height = video.videoHeight;\n",
        "              canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "              stream.getVideoTracks()[0].stop();\n",
        "              div.remove();\n",
        "              resolve(canvas.toDataURL('image/jpeg', quality));\n",
        "            }\n",
        "\n",
        "            // Wait for 'q' key press to exit.\n",
        "            document.addEventListener('keydown', (e) => {\n",
        "              if (e.key === 'q') {\n",
        "                stream.getVideoTracks()[0].stop();\n",
        "                div.remove();\n",
        "                resolve(null);\n",
        "              }\n",
        "            });\n",
        "          });\n",
        "\n",
        "          return result;\n",
        "        }\n",
        "    ''')\n",
        "    display(js)\n",
        "    data = eval_js('takePhoto({})'.format(quality))\n",
        "    if data is not None:\n",
        "        binary = b64decode(data.split(',')[1])\n",
        "        with open(filename, 'wb') as f:\n",
        "            f.write(binary)\n",
        "    return data\n",
        "\n",
        "# Take a photo using Colab's webcam capture\n",
        "result = take_photo()\n",
        "\n",
        "# Check if a photo was taken and the 'q' key was not pressed\n",
        "if result is not None:\n",
        "    vs = cv2.VideoCapture('photo.jpg')\n",
        "    # Rest of your code...\n",
        "\n",
        "while True:\n",
        "    ret, frame = vs.read()\n",
        "\n",
        "    # Check if the frame was successfully read\n",
        "    if not ret:\n",
        "        print(\"Error reading frame. Exiting...\")\n",
        "        break\n",
        "\n",
        "    frame = imutils.resize(frame, width=450)\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "\n",
        "    # Detect faces in the frame using Haar Cascade\n",
        "    rects = detector.detectMultiScale(gray, scaleFactor=1.1,\n",
        "                                      minNeighbors=5, minSize=(30, 30),\n",
        "                                      flags=cv2.CASCADE_SCALE_IMAGE)\n",
        "\n",
        "    for (x, y, w, h) in rects:\n",
        "        rect = dlib.rectangle(int(x), int(y), int(x + w), int(y + h))\n",
        "\n",
        "        shape = predictor(gray, rect)\n",
        "        shape = face_utils.shape_to_np(shape)\n",
        "\n",
        "        eye = final_ear(shape)\n",
        "        ear = eye[0]\n",
        "        leftEye = eye[1]\n",
        "        rightEye = eye[2]\n",
        "\n",
        "        distance = lip_distance(shape)\n",
        "\n",
        "        leftEyeHull = cv2.convexHull(leftEye)\n",
        "        rightEyeHull = cv2.convexHull(rightEye)\n",
        "        cv2.drawContours(frame, [leftEyeHull], -1, (0, 255, 0), 1)\n",
        "        cv2.drawContours(frame, [rightEyeHull], -1, (0, 255, 0), 1)\n",
        "\n",
        "        lip = shape[48:60]\n",
        "        cv2.drawContours(frame, [lip], -1, (0, 255, 0), 1)\n",
        "\n",
        "        # Check for drowsiness\n",
        "        if ear < EYE_AR_THRESH:\n",
        "            COUNTER += 1\n",
        "\n",
        "            if COUNTER >= EYE_AR_CONSEC_FRAMES:\n",
        "                if alarm_status == False:\n",
        "                    alarm_status = True\n",
        "                    t = Thread(target=alarm, args=('Wake up, sir!',))\n",
        "                    t.deamon = True\n",
        "                    t.start()\n",
        "\n",
        "                cv2.putText(frame, \"DROWSINESS ALERT!\", (10, 30),\n",
        "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
        "        else:\n",
        "            COUNTER = 0\n",
        "            alarm_status = False\n",
        "\n",
        "        # Check for yawn\n",
        "        if distance > YAWN_THRESH:\n",
        "            cv2.putText(frame, \"Yawn Alert\", (10, 30),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
        "            if alarm_status2 == False and saying == False:\n",
        "                alarm_status2 = True\n",
        "                t = Thread(target=alarm, args=('Take some fresh air, sir!',))\n",
        "                t.deamon = True\n",
        "                t.start()\n",
        "        else:\n",
        "            alarm_status2 = False\n",
        "\n",
        "        # Display EAR and YAWN values on the frame\n",
        "        cv2.putText(frame, \"EAR: {:.2f}\".format(ear), (300, 30),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
        "        cv2.putText(frame, \"YAWN: {:.2f}\".format(distance), (300, 60),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
        "\n",
        "    # Show the frame\n",
        "    from google.colab.patches import cv2_imshow\n",
        "    cv2_imshow(frame)\n",
        "\n",
        "    if key == ord(\"q\"):\n",
        "        break\n",
        "\n",
        "cv2.destroyAllWindows()\n",
        "vs.release()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "fb6bae64-bffb-4a76-ffb2-32aef7e09d92",
        "id": "jSqYqAxo7MGO"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "usage: colab_kernel_launcher.py [-h] [-w WEBCAM]\n",
            "colab_kernel_launcher.py: error: unrecognized arguments: -f /root/.local/share/jupyter/runtime/kernel-52efdb79-6184-44f5-b1ec-334026b98d4b.json\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        }
      ]
    }
  ]
}